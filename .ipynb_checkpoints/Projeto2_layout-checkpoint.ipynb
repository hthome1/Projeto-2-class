{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Henrique Thomé\n",
    "\n",
    "Nome: _____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: ***[Preencha aqui o id da sua conta. Ex: @fulano ]***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Dados de autenticação do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @fulano\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. Não modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'Motorola One'\n",
    "\n",
    "#Quantidade mínima de mensagens capturadas:\n",
    "n = 600\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "t = 300\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():    \n",
    "    msgs.append(msg.full_text.lower())\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um possível viés\n",
    "shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.drop_duplicates(subset =\"Treinamento\", keep = False, inplace = True) \n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.drop_duplicates(subset =\"Teste\", keep = False, inplace = True) \n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_teste = pd.read_excel('Motorola One.xlsx',sheet_name='Teste')\n",
    "dados_treinamento = pd.read_excel('Motorola One.xlsx',sheet_name='Treinamento')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Função de limpeza muito simples que troca alguns sinais básicos por espaços\n",
    "    \"\"\"\n",
    "    punctuation = '[!\\-.:?;,]' # Note que os sinais [] são delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_rel = dados_treinamento[dados_treinamento['Class']==1]\n",
    "textao = ' '.join(df_rel['Treinamento'])\n",
    "textao_limpo = cleanup(textao)\n",
    "lista_palavras = textao_limpo.split()\n",
    "freq_abs_rel = pd.Series(lista_palavras).value_counts()\n",
    "contagem_rel= dict(freq_abs_rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ir = dados_treinamento[dados_treinamento['Class']==0]\n",
    "textaoir = ' '.join(df_ir['Treinamento'])\n",
    "textao_limpoir = cleanup(textaoir)\n",
    "lista_palavrasir = textao_limpoir.split()\n",
    "freq_abs_ir = pd.Series(lista_palavrasir).value_counts()\n",
    "contagem_ir= dict(freq_abs_ir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_palavras(dicionario):\n",
    "    contador = 0\n",
    "    for e in dicionario:\n",
    "        contador+=dicionario[e]\n",
    "    return contador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contando o total de palavras para fazer o Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_palavras_ir = total_palavras(contagem_ir)\n",
    "total_palavras_rel = total_palavras(contagem_rel)\n",
    "total_geral = len(contagem_ir) + len(contagem_rel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Classificando as mensagens na coragem\n",
    "\n",
    "Esta etapa é manual. Faça a mesma pelo Excel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Montando um dicionario com a probabilidade das palavras que já existem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_rel = {}\n",
    "for e in contagem_rel:\n",
    "    prob_rel[e] = (contagem_rel[e] + 1)/(total_palavras_rel + total_geral)\n",
    "prob_ir = {}\n",
    "for e in contagem_ir:\n",
    "    prob_ir[e] = (contagem_ir[e]+1)/(total_palavras_ir + total_geral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Montando um dicionario com a prob das palavras no df teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = dados_teste['Teste']\n",
    "text = ' '.join(new_df)\n",
    "textao_lim = cleanup(text)\n",
    "lista_pala = textao_lim.split()\n",
    "freq = pd.Series(lista_pala).value_counts()\n",
    "cont= dict(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rel = {}\n",
    "test_ir = {}\n",
    "for e in cont.keys():\n",
    "    if e not in prob_rel:\n",
    "        test_rel[e] = 1/(total_palavras_rel + total_geral)\n",
    "    else:\n",
    "        test_rel[e] = (contagem_rel[e] + 1)/(total_palavras_rel + total_geral)\n",
    "for e in cont.keys():\n",
    "    if e not in prob_ir:\n",
    "        test_ir[e] = 1/(total_palavras_ir + total_geral)\n",
    "    else:\n",
    "        test_ir[e] = (contagem_ir[e] + 1)/(total_palavras_ir + total_geral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = new_df.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['motorola', 'one', 'zoom', 'vem', 'com', '48mp', 'e', 'zoom', '3x', 'https', '//t', 'co/1eqg40fm1a']\n"
     ]
    }
   ],
   "source": [
    "lista = []\n",
    "lista_nova = []\n",
    "for e in x:\n",
    "    lista.append(cleanup(e))\n",
    "for e in lista:\n",
    "    lista_nova.append(e.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = []\n",
    "contador = 0 \n",
    "for e in lista_nova:\n",
    "    contador+=1\n",
    "    re = 1\n",
    "    ir = 1\n",
    "    for x in e:\n",
    "        re*=test_rel[x]\n",
    "        ir*= test_ir[x]\n",
    "    if re > ir:\n",
    "                resultado.append(1)\n",
    "    else:\n",
    "                resultado.append(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_certo = (dados_teste['Class'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "positivo = 0\n",
    "negativo = 0\n",
    "falso_positivo = 0\n",
    "falso_negativo = 0\n",
    "for i in range(0,len(resultado_certo)):\n",
    "    if resultado_certo[i] == 0 and resultado[i] == 0:\n",
    "        negativo +=1\n",
    "    elif resultado_certo[i] == 1 and resultado[i] == 1:\n",
    "        positivo +=1\n",
    "    elif resultado_certo[i] == 1 and resultado[i] == 0:\n",
    "        falso_negativo +=1\n",
    "    elif resultado_certo[i] == 0 and resultado[i] == 1:\n",
    "        falso_positivo+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dados_teste[dados_teste['Class']==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positivo 0.1477832512315271\n",
      "Negativo 0.6059113300492611\n",
      "Falso Negativo 0.059113300492610835\n",
      "Falso Positivo 0.18719211822660098\n",
      "Acuracia 0.7536945812807881\n",
      "total de negativos na base teste 0.7931034482758621\n"
     ]
    }
   ],
   "source": [
    "print('Positivo',positivo/203)\n",
    "print('Negativo',negativo/203)\n",
    "print('Falso Negativo',falso_negativo/203)\n",
    "print('Falso Positivo',falso_positivo/203)\n",
    "print('Acuracia',(positivo+negativo)/203)\n",
    "print('total de negativos na base teste',len(dados_teste[dados_teste['Class']==0])/203)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nosso classificador chegou a uma acurrácia de aproximadamente 75%. Esse resultado, em príncipio parece bastante satisfatório, uma vez que não temos uma grande quantidade de dados e a limpeza do texto está relativamente rudimentar. Ao analizarmos mais a fundo os dados é possível observar que a grande maioria dos dados para o treinamento foram tweets negativos (não relevantes). Assim pode-se pensar que o classificador poderia estar classificando a maioria das frases como negativas e tendo, por isso, um bom desempenho. \n",
    "Esse hipótese mostra-se errada, uma vez que a maior parte dos erros foi de falsos positivos, indicando que a maquina não classificou do modo como pensávamos, mostrando assim que o computador foi capaz de reconhecer padrões nos comentários. Apesar disso, o programa mostra-se ineficiente, uma vez que se ele classificasse todos os tweets como negativos teria uma porcentagem maior de acertos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Para aperfeiçoar o classificador é possível retirar links, @ e rts, pois esses não influenciam a classificação da palavras. Além disso para o classificador ser o mais preciso possível era necessário selecionar só as palavras chaves de cada tweet, tirando assim tudo que não importa. Para fazer isso, um novo classificador do tipo naive-bayes poderia ser criado, com um database classificando apenas as palavras chaves do texto. Dessa forma o primeiro programa selecionaria apenas as palavras chaves, enquanto o segundo as classificaria em irrelevante e relevante.\n",
    "##### Ao analisar as mensagem foi possível perceber que o número de frases irrelevantes e muito maior que o de relevantes. Isso pode ocasionar resultados falsos, uma vez que se o classificador der sempre irrelevante ele tem grandes chances de estar certo.\n",
    "##### Não podemos usar o classificador para gerar mais amostras de treinamento, pois se isso fosse teriamos uma amostra viciada, ou seja, o dicionario com as probabilidades de relevantes e irrelevantes nunca seriam alterados e, portanto os resultados seriam os mesmos\n",
    "#### Existem milhares de aplicações para programas como esse. Um exemplo disso seria um analizador sentimental para avaliar contratações por times de futebol. Dessa forma a diretoria do clube saberia se o possível reforço tem uma boa aceitação pela torcida. Também existem milhares de aplicações para o governo, que por meio do programa poderia saber se a população está gostando do seu trabalho ou de uma determinada proposta de lei"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
